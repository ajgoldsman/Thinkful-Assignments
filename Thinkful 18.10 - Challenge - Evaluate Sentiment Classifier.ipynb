{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the TXT from the ZIP file\n",
    "import zipfile\n",
    "filename = \"Documents/Thinkful/Module 18/sentiment_labelled_sentences.zip\"\n",
    "\n",
    "zf = zipfile.ZipFile(filename)\n",
    "imdb_raw = pd.read_csv(zf.open('sentiment labelled sentences/imdb_labelled.txt'), delimiter = '\\t', header=None)\n",
    "imdb_raw.columns = ['message', 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  sentiment\n",
       "0  A very, very, very slow-moving, aimless movie ...          0\n",
       "1  Not sure who was more lost - the flat characte...          0\n",
       "2  Attempting artiness with black & white and cle...          0\n",
       "3       Very little music or anything to speak of.            0\n",
       "4  The best scene in the movie was when Gerardo i...          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a very very very slow-moving aimless movie abo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not sure who was more lost the flat characters...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>very little music or anything to speak of</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the best scene in the movie was when gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  sentiment\n",
       "0  a very very very slow-moving aimless movie abo...          0\n",
       "1  not sure who was more lost the flat characters...          0\n",
       "2  attempting artiness with black & white and cle...          0\n",
       "3        very little music or anything to speak of            0\n",
       "4  the best scene in the movie was when gerardo i...          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clean the data so we can extract similar words, i.e. turn everything lowercase and remove punctuation\n",
    "clean_msg = [row.lower()\n",
    "           .replace(\",\", \"\").replace(\".\", \"\").replace(\"!\", \"\").replace(\"?\", \"\")\n",
    "           .replace(\";\", \"\").replace(\":\", \"\").replace(\"*\", \"\")\n",
    "           .replace(\" - \", \" \").replace(\"(\", \"\")\n",
    "           .replace(\")\", \"\").replace(\"/\", \"\")\n",
    "           for row in imdb_raw['message']]\n",
    "\n",
    "imdb_raw['message'] = clean_msg\n",
    "imdb_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into two datasets: positive and negative\n",
    "pos_msg = imdb_raw['message'][imdb_raw['sentiment']==1]\n",
    "pos_msg = list(pos_msg.reset_index(drop=True))\n",
    "\n",
    "neg_msg = imdb_raw['message'][imdb_raw['sentiment']==0]\n",
    "neg_msg = list(neg_msg.reset_index(drop=True))\n",
    "\n",
    "#Combine all strings into one long string for each dataset\n",
    "seperator = ' '\n",
    "pos_long = seperator.join(pos_msg)\n",
    "neg_long = seperator.join(neg_msg)\n",
    "\n",
    "#Extract words and number of repeats in each dataset\n",
    "from collections import Counter\n",
    "pos_counts = Counter(pos_long.split())\n",
    "neg_counts = Counter(neg_long.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get list of positive and negative words that appear at least twice\n",
    "pos_words = [x[0] for x in pos_counts.most_common() if x[1] >= 2]\n",
    "neg_words = [x[0] for x in neg_counts.most_common() if x[1] >= 2]\n",
    "\n",
    "#Remove any words that appear in both lists\n",
    "for word in pos_words[:]:\n",
    "    if word in neg_words:\n",
    "        pos_words.remove(word)\n",
    "        neg_words.remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that we have a list of positive and negative keywords, compare them to all messages\n",
    "for word in pos_words:\n",
    "    imdb_raw['Positive: ' + str(word)] = imdb_raw.message.str.contains(' ' + str(word) + ' ', case=False)\n",
    "    \n",
    "for word in neg_words:\n",
    "    imdb_raw['Negative: ' + str(word)] = imdb_raw.message.str.contains(' ' + str(word) + ' ', case=False)\n",
    "       \n",
    "#Convert sentiment column into boolean for positive sentiment\n",
    "imdb_raw['sentiment'] = (imdb_raw['sentiment'] == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Bernoulli to test for accuracy of the model based on current keywords\n",
    "data = imdb_raw[imdb_raw.columns.drop(['message','sentiment'])]\n",
    "target = imdb_raw['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score when using the entire sample: 0.86\n"
     ]
    }
   ],
   "source": [
    "# Train model and test, using entire data set, as in Module 18.6\n",
    "bnb1 = BernoulliNB()\n",
    "bnb1.fit(data, target)\n",
    "score1 = bnb1.score(data, target)\n",
    "\n",
    "print(\"Score when using the entire sample: \" + str(round(score1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with 20% Holdout: 0.8266666666666667\n"
     ]
    }
   ],
   "source": [
    "#Test the model with holdout groups\n",
    "from sklearn.model_selection import train_test_split\n",
    "bnb2 = BernoulliNB()\n",
    "\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('Score with 20% Holdout: ' + str(bnb2.fit(X_train, y_train).score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores when cross-validation is used with 10 folds \n",
      " [0.80263158 0.77631579 0.82666667 0.74666667 0.74666667 0.76\n",
      " 0.77027027 0.7972973  0.67567568 0.75675676]\n"
     ]
    }
   ],
   "source": [
    "#Test the model via cross-validation (10 folds)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "bnb3 = BernoulliNB()\n",
    "folds = 10\n",
    "scores3 = cross_val_score(bnb3, data, target, cv=folds)\n",
    "\n",
    "print(\"Scores when cross-validation is used with 10 folds \\n\", scores3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune parameters to improve accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy is obtained with a random_state value of:  37\n",
      "Maximum accuracy is obtained with a holdout group_size of:  0.1\n",
      "When both optimized values are used, the calculated accuracy is:  0.88\n"
     ]
    }
   ],
   "source": [
    "#Tune size of holdout group and parameter 'random_state' used for initializing the random number generator\n",
    "bnb4 = BernoulliNB()\n",
    "group_size = []\n",
    "random_state = []\n",
    "values = []\n",
    "\n",
    "for i in range(100):    #range of possible random_state values (100 is an aribitrary range. It could be larger or smaller, as needed)\n",
    "    for size in np.arange(0.10,0.55,0.05):      #range of possible holdout group sizes\n",
    "        size = round(size,2)     #some values in the array may have weird extra decimals\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=size, random_state=i)\n",
    "        values.append(round(bnb4.fit(X_train, y_train).score(X_test, y_test),2))\n",
    "        random_state.append(i)\n",
    "        group_size.append(size)\n",
    "        \n",
    "ind = values.index(max(values))    #index where the optimized value is located\n",
    "print(\"Maximum accuracy is obtained with a random_state value of: \", random_state[ind])\n",
    "print(\"Maximum accuracy is obtained with a holdout group_size of: \", group_size[ind])\n",
    "print(\"When both optimized values are used, the calculated accuracy is: \", max(values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy is obtained with 15 folds.\n",
      "When 15 folds are used, the cross-validation values are: \n",
      "[0.76, 0.82, 0.82, 0.84, 0.74, 0.78, 0.74, 0.84, 0.78, 0.78, 0.86, 0.76, 0.57, 0.82, 0.76]\n"
     ]
    }
   ],
   "source": [
    "#Tune number of folds to optimize cross-validation accuracy\n",
    "bnb5 = BernoulliNB()\n",
    "scores5 = []\n",
    "cross_val = []\n",
    "avg_acc = []\n",
    "folds = list(range(2,20))     #Arbitrary range of folds. Could have done more or fewer.\n",
    "\n",
    "for fold in folds:\n",
    "    scores5 = cross_val_score(bnb5, data, target, cv=fold)\n",
    "    avg_acc.append(round(scores5.mean(),2))    #greatest average accuracy\n",
    "    cross_val.append([round(x,2) for x in scores5])\n",
    "    \n",
    "ind = avg_acc.index(max(avg_acc))    #index where the optimized value is located\n",
    "print(\"Maximum accuracy is obtained with {} folds.\".format(folds[ind]))\n",
    "print(\"When {} folds are used, the cross-validation values are: \\n{}\".format(folds[ind], cross_val[ind]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results of the test using holdout groups and cross-validation, I don't believe my classifier has overfit, since all of the values come out to approximately 80-86%, which shows that there isn't a significant difference between separated groups. The test in which I used an optimized random_state value and holdout group size provided the greatest overall accuracy (88%), which makes sense, as it was by that method that I iterated through hundreds of possible combinations. Performance of the model seems to be most impacted by the number of folds in cross-validation and the size of the holdout group."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
